{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df = pd.read_csv(r\"C:\\Users\\hvvel\\Downloads/tweet_translated.csv\",engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38360, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           id                                          text_data  profane_class\n",
       "6478    6478  Dear inconsiderate ghetto shit on the train in...              1\n",
       "26131  26131                          It has one Wrestlinglvoer              0\n",
       "11719  11719  Tell me I'm beautiful like you say to all the ...              1\n",
       "22081  22081  Question   HiI was just wondering if this seas...              0\n",
       "36631  36631   With respect to the article on Tejas please t...              0\n",
       "...      ...                                                ...            ...\n",
       "24241  24241          Many thanks Technopat for drawing the ...              0\n",
       "29387  29387       Removed those entries that are SMP clustered              0\n",
       "24896  24896   sorry i have problems being  called usual sub...              0\n",
       "26666  26666   Your mother looks like a toughasnails birdI s...              0\n",
       "35573  35573  Kilgarvans population is calculated using DED ...              0\n",
       "\n",
       "[38360 rows x 3 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df = back_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hvvel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "# pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine\n",
    "# has been programmed to ignore, both when indexing entries for searching and when retrieving them \n",
    "# as the result of a search query.\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df[\"text_data\"] = back_df.text_data.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count unique words\n",
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "counter = counter_word(back_df.text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66494"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bitch', 5910),\n",
       " ('article', 5689),\n",
       " ('like', 5174),\n",
       " ('page', 4859),\n",
       " ('talk', 3593)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words = len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into training and test set\n",
    "random.seed(100)\n",
    "train_size = int(back_df.shape[0] * 0.7)\n",
    "\n",
    "train_df = back_df[:train_size]\n",
    "test_df = back_df[train_size:]\n",
    "\n",
    "# split text and labels\n",
    "train_sentences = train_df.text_data.to_numpy()\n",
    "train_labels = train_df.profane_class.to_numpy()\n",
    "test_sentences = test_df.text_data.to_numpy()\n",
    "test_labels = test_df.profane_class.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26852,), (11508,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.shape, test_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# vectorize a text corpus by turning each text into a sequence of integers\n",
    "tokenizer = Tokenizer(num_words=num_unique_words)\n",
    "tokenizer.fit_on_texts(train_sentences) # fit only to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear inconsiderate ghetto shit train front know phone options right phone speaker'\n",
      " 'one wrestlinglvoer' \"tell i'm beautiful like say bitches.\"\n",
      " 'question hii wondering season still'\n",
      " 'respect article tejas please tell revisions removed sources bloggers far tell indian media outlets addition insisted changing type radar aircraft supposedly equipped without actually providing source substantiating claim provide credible source dead link way protest edit note still havent removed source added even though accessible link anymore']\n",
      "[[878, 7676, 507, 32, 2642, 1040, 13, 807, 2994, 44, 807, 5459], [7, 21257], [147, 28, 1272, 3, 35, 10], [152, 21258, 1113, 1114, 53], [576, 2, 21259, 9, 147, 5117, 123, 50, 14861, 230, 147, 990, 319, 7677, 714, 11755, 879, 633, 6382, 2373, 3330, 14862, 97, 155, 2112, 60, 21260, 280, 439, 1695, 60, 778, 103, 42, 3223, 21, 114, 53, 489, 123, 60, 132, 29, 175, 3624, 103, 981]]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[0:5])\n",
    "print(train_sequences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26852.000000\n",
       "mean        18.654774\n",
       "std         35.945907\n",
       "min          0.000000\n",
       "25%          5.000000\n",
       "50%          9.000000\n",
       "75%         15.000000\n",
       "max       1000.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sequences = []\n",
    "for one_seq in train_sentences:\n",
    "    word_list = one_seq.split() \n",
    "    #print(len(word_list))\n",
    "    len_sequences.append(len(word_list))\n",
    "#print(len_sequences)\n",
    "pd.Series(len_sequences).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26852, 50), (11508, 50))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Pad the sequences to have the same length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Max number of words in a sequence\n",
    "max_length = 50\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "train_padded.shape, test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 32)            2127808   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,152,705\n",
      "Trainable params: 2,152,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Embedding: https://www.tensorflow.org/tutorials/text/word_embeddings\n",
    "# Turns positive integers (indexes) into dense vectors of fixed size. (other approach could be one-hot-encoding)\n",
    "\n",
    "# Word embeddings give us a way to use an efficient, dense representation in which similar words have \n",
    "# a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a \n",
    "# dense vector of floating point values (the length of the vector is a parameter you specify).\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n",
    "\n",
    "# The layer will take as input an integer matrix of size (batch, input_length),\n",
    "# and the largest integer (i.e. word index) in the input should be no larger than num_words (vocabulary size).\n",
    "# Now model.output_shape is (None, input_length, 32), where `None` is the batch dimension.\n",
    "\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=0.1))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "756/756 - 28s - loss: 0.4571 - accuracy: 0.8017 - val_loss: 0.4538 - val_accuracy: 0.8038\n",
      "Epoch 2/20\n",
      "756/756 - 23s - loss: 0.4511 - accuracy: 0.7965 - val_loss: 0.4629 - val_accuracy: 0.7777\n",
      "Epoch 3/20\n",
      "756/756 - 36s - loss: 0.3738 - accuracy: 0.8202 - val_loss: 0.2341 - val_accuracy: 0.9088\n",
      "Epoch 4/20\n",
      "756/756 - 36s - loss: 0.1663 - accuracy: 0.9462 - val_loss: 0.1247 - val_accuracy: 0.9576\n",
      "Epoch 5/20\n",
      "756/756 - 29s - loss: 0.0631 - accuracy: 0.9794 - val_loss: 0.1044 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "756/756 - 23s - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.1166 - val_accuracy: 0.9643\n",
      "Epoch 7/20\n",
      "756/756 - 19s - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.1507 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "756/756 - 19s - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.1517 - val_accuracy: 0.9650\n",
      "Epoch 9/20\n",
      "756/756 - 19s - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.1996 - val_accuracy: 0.9605\n",
      "Epoch 10/20\n",
      "756/756 - 22s - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.2037 - val_accuracy: 0.9587\n",
      "Epoch 11/20\n",
      "756/756 - 23s - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.2099 - val_accuracy: 0.9576\n",
      "Epoch 12/20\n",
      "756/756 - 22s - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.2078 - val_accuracy: 0.9609\n",
      "Epoch 13/20\n",
      "756/756 - 23s - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1796 - val_accuracy: 0.9628\n",
      "Epoch 14/20\n",
      "756/756 - 23s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2717 - val_accuracy: 0.9602\n",
      "Epoch 15/20\n",
      "756/756 - 23s - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.2462 - val_accuracy: 0.9587\n",
      "Epoch 16/20\n",
      "756/756 - 23s - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2524 - val_accuracy: 0.9587\n",
      "Epoch 17/20\n",
      "756/756 - 25s - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1712 - val_accuracy: 0.9520\n",
      "Epoch 18/20\n",
      "756/756 - 24s - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.2297 - val_accuracy: 0.9620\n",
      "Epoch 19/20\n",
      "756/756 - 24s - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.2117 - val_accuracy: 0.9635\n",
      "Epoch 20/20\n",
      "756/756 - 24s - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.2468 - val_accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a184316c88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded, train_labels, epochs=20, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_padded)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trash'\n",
      " 'well used avoid seem irresistably drawn trying resolve brushfire wars hopefully something satisfactory come one conspire past ops'\n",
      " \"know wouldn't.\"\n",
      " 'im sorry feeling experience check block log rr blocks year ago three due reports filed one vanished editor editwarring time faced sanctions last one due rr report filed editor since banned sockpuppet blocked reverting edits twice anyway interesting proposal id like help however talk'\n",
      " 'please ronald mallet john titor time travel articles fringe science published gave code sources web sources news paper sources ronald mallet oh please'\n",
      " 'oh, please, faggot.'\n",
      " \"let retards go food store, step boots foodtown, yall knows step blacks' shoes.\"\n",
      " 'first thing zombie outbreak sell hoe'\n",
      " 'bitch ralphy thanks tcoaakwohdfgv' 'men biggest hoes lmmao']\n",
      "[0 0 1 0 0 1 1 1 1 1]\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_sentences[10:20])\n",
    "\n",
    "print(test_labels[10:20])\n",
    "print(predictions[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604622871046229"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9652679830747531"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9549973835688121"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
