{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chahHcKo_Aty"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from gensim import corpora,models,similarities\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGNJX15Z_At2"
   },
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmQTQ-1x_At3"
   },
   "outputs": [],
   "source": [
    "dataF = pd.read_excel(\"original+bt_data.xlsx\",names=['Text_id', 'text_data','profane_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "ccGRvj8a_At3",
    "outputId": "2a7e6f7c-d503-402a-c953-35fd16bd7bae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_id</th>\n",
       "      <th>text_data</th>\n",
       "      <th>profane_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lmaoooo   Lol OK pal   what bitch gone tell me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>These whores are loyal.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I came here to ask the same question Their use...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>REDIRECT TalkChallenge Chateau Cartier de Gati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Template English Scottish and British monarchs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't even tell a bitch hey without thinking...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Sep   Archive Archive  Sep</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Notability of Michael Fout  A tag has been pla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>The meanest bitch didn't win Queen Fuck the Me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>You're not right for this job. Why good your r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text_id                                          text_data  profane_class\n",
       "0        0  lmaoooo   Lol OK pal   what bitch gone tell me...              1\n",
       "1        1                            These whores are loyal.              1\n",
       "2        2  I came here to ask the same question Their use...              0\n",
       "3        3  REDIRECT TalkChallenge Chateau Cartier de Gati...              0\n",
       "4        4  Template English Scottish and British monarchs...              0\n",
       "5        5  I can't even tell a bitch hey without thinking...              1\n",
       "6        6                         Sep   Archive Archive  Sep              0\n",
       "7        7  Notability of Michael Fout  A tag has been pla...              0\n",
       "8        8  The meanest bitch didn't win Queen Fuck the Me...              1\n",
       "9        9  You're not right for this job. Why good your r...              1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjONQSVD_At4",
    "outputId": "2ca3995d-88f1-49b1-92a8-53567a98c8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the original dataset:\n",
      "\n",
      "Index(['Text_id', 'text_data', 'profane_class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the original dataset:\\n\")\n",
    "print(dataF.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "rFKNkIdL_At4",
    "outputId": "fc8869ae-2167-475c-d8eb-0720cbabca59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per star rating:\n",
      "0    46863\n",
      "1    46829\n",
      "Name: profane_class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(dataF['profane_class'].value_counts())\n",
    "\n",
    "# Function to map stars to sentiment\n",
    "def map_sentiment(profane_class):\n",
    "    if profane_class == 1:\n",
    "        return 1\n",
    "    elif profane_class == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "# Mapping stars to sentiment into three categories\n",
    "dataF['sentiment'] = [ map_sentiment(x) for x in dataF['profane_class']]\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(dataF['sentiment']).plot.bar(title=\"Sentiment distribution in dF\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in dF\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENgIewx5_At5",
    "outputId": "4f9d69fc-d27e-42b7-af3d-c0e078ce3c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They good service!!\n"
     ]
    }
   ],
   "source": [
    "# Removing the stop words\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "print(remove_stopwords(\"They had a good service!!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LdwyzVe_At5",
    "outputId": "d373274d-c46d-4224-dcbe-a2aff446248e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [lmaoooo, lol, ok, pal, what, bitch, gone, tel...\n",
      "1                          [these, whores, are, loyal]\n",
      "2    [came, here, to, ask, the, same, question, the...\n",
      "3    [redirect, talkchallenge, chateau, cartier, de...\n",
      "4    [template, english, scottish, and, british, mo...\n",
      "5    [can, even, tell, bitch, hey, without, thinkin...\n",
      "6                         [sep, archive, archive, sep]\n",
      "7    [notability, of, michael, fout, tag, has, been...\n",
      "8    [the, meanest, bitch, didn, win, queen, fuck, ...\n",
      "9    [you, re, not, right, for, this, job, why, goo...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "dataF['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in dataF['text_data']] \n",
    "print(dataF['tokenized_text'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkUwMTQB_At6",
    "outputId": "ca30de83-1a23-4c12-9c81-66ecab48fa06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [lmaoooo, lol, ok, pal, what, bitch, gone, tel...\n",
       "1                            [these, whore, ar, loyal]\n",
       "2    [came, here, to, ask, the, same, question, the...\n",
       "3    [redirect, talkchalleng, chateau, cartier, de,...\n",
       "4    [templat, english, scottish, and, british, mon...\n",
       "5    [can, even, tell, bitch, hei, without, think, ...\n",
       "6                           [sep, archiv, archiv, sep]\n",
       "7    [notabl, of, michael, fout, tag, ha, been, pla...\n",
       "8    [the, meanest, bitch, didn, win, queen, fuck, ...\n",
       "9    [you, re, not, right, for, thi, job, why, good...\n",
       "Name: stemmed_tokens, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Get the stemmed_tokens\n",
    "dataF['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in dataF['tokenized_text'] ]\n",
    "dataF['stemmed_tokens'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hML7FuX4_At7",
    "outputId": "417790cc-b889-4a90-df95-a696362cd93c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "0    32828\n",
      "1    32756\n",
      "Name: sentiment, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "1    14073\n",
      "0    14035\n",
      "Name: sentiment, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "   index  ...                                     stemmed_tokens\n",
      "0  63212  ...  [hello, keep, get, messag, from, anoth, user, ...\n",
      "1  26934  ...  [the, power, of, christ, forc, you, to, blow, ...\n",
      "2  76573  ...  [as, in, natur, biologi, dog, dont, eat, each,...\n",
      "3   1674  ...  [hello, go, back, to, your, own, countri, you,...\n",
      "4  45924  ...                            [we, aint, friend, hoe]\n",
      "\n",
      "[5 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train Test Split Function\n",
    "def split_train_test(dataF, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(dataF[['Text_id','text_data','profane_class','stemmed_tokens']], \n",
    "                                                        dataF['sentiment'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(dataF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqNB3Bmv_At8"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as FF\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uiub8Dmr_At8",
    "outputId": "579af69d-f44d-4d57-d787-1d9ecacd0e00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F4f-5dF_At8"
   },
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        \n",
    "        # Linear function 1: vocab_size --> 500\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 500 --> 500\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3 (readout): 500 --> 3\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 3 (readout)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return FF.softmax(out, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrO8mr9S_At9",
    "outputId": "a2985bc2-7556-4665-89f9-5ff8ada55698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary without padding\n",
      "       Text_id  ...                                     stemmed_tokens\n",
      "0            0  ...  [lmaoooo, lol, ok, pal, what, bitch, gone, tel...\n",
      "1            1  ...                          [these, whore, ar, loyal]\n",
      "2            2  ...  [came, here, to, ask, the, same, question, the...\n",
      "3            3  ...  [redirect, talkchalleng, chateau, cartier, de,...\n",
      "4            4  ...  [templat, english, scottish, and, british, mon...\n",
      "...        ...  ...                                                ...\n",
      "93687    93687  ...                            [twitter, watch, bitch]\n",
      "93688    93688  ...  [so, go, and, fuck, yourself, jame, watson, an...\n",
      "93689    93689  ...  [next, time, add, it, quicker, you, sorri, sac...\n",
      "93690    93690  ...  [milton, friedman, etc, realli, dont, know, wh...\n",
      "93691    93691  ...         [bind, tortur, kill, that, my, philosophi]\n",
      "\n",
      "[93692 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# Function to return the dictionary either with padding word or without padding\n",
    "def m_dict(dataF, padding=True):\n",
    "    if padding:\n",
    "        print(\"Dictionary with padded token added\")\n",
    "        print(dataF)\n",
    "        r_dict = corpora.Dictionary([['pad']])\n",
    "        r_dict.add_documents(dataF['stemmed_tokens'])\n",
    "    else:\n",
    "        print(\"Dictionary without padding\")\n",
    "        print(dataF)\n",
    "        r_dict = corpora.Dictionary(dataF['stemmed_tokens'])\n",
    "    return r_dict\n",
    "# Make the dictionary without padding for the basic models\n",
    "r_dict = m_dict(dataF, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rAKym_c_At9"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(r_dict)\n",
    "NUM_LABELS = 3\n",
    "\n",
    "# Function to make bow vector to be used as input to network\n",
    "def make_bow_vector(r_dict, sentence):\n",
    "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
    "    for word in sentence:\n",
    "        vec[r_dict.token2id[word]] += 1\n",
    "    return vec.view(1, -1).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WU03SF4Y_At9"
   },
   "outputs": [],
   "source": [
    "# Function to get the output tensor\n",
    "def make_target(label):\n",
    "    if label == -1:\n",
    "        return torch.tensor([0], dtype=torch.long, device=device)\n",
    "    elif label == 0:\n",
    "        return torch.tensor([1], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        return torch.tensor([2], dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LIz0RQL_At-"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(r_dict)\n",
    "\n",
    "input_dim = VOCAB_SIZE\n",
    "hidden_dim = 500\n",
    "output_dim = 3\n",
    "num_epochs = 100\n",
    "\n",
    "ff_nn_bow_model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "ff_nn_bow_model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ff_nn_bow_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Do8fIxoDIfR"
   },
   "outputs": [],
   "source": [
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI6nedEy_At-",
    "outputId": "df07a2de-bcf4-43d1-a738-9f50a4048dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch completed: 1\n",
      "Epoch completed: 2\n",
      "Epoch completed: 3\n",
      "Epoch completed: 4\n",
      "Epoch completed: 5\n",
      "Epoch completed: 6\n",
      "Epoch completed: 7\n",
      "Epoch completed: 8\n",
      "Epoch completed: 9\n",
      "Epoch completed: 10\n",
      "Epoch completed: 11\n",
      "Epoch completed: 12\n",
      "Epoch completed: 13\n",
      "Epoch completed: 14\n",
      "Epoch completed: 15\n",
      "Epoch completed: 16\n",
      "Epoch completed: 17\n",
      "Epoch completed: 18\n",
      "Epoch completed: 19\n",
      "Epoch completed: 20\n",
      "Epoch completed: 21\n",
      "Epoch completed: 22\n",
      "Epoch completed: 23\n",
      "Epoch completed: 24\n",
      "Epoch completed: 25\n",
      "Epoch completed: 26\n",
      "Epoch completed: 27\n",
      "Epoch completed: 28\n",
      "Epoch completed: 29\n",
      "Epoch completed: 30\n",
      "Epoch completed: 31\n",
      "Epoch completed: 32\n",
      "Epoch completed: 33\n",
      "Epoch completed: 34\n",
      "Epoch completed: 35\n",
      "Epoch completed: 36\n",
      "Epoch completed: 37\n",
      "Epoch completed: 38\n",
      "Epoch completed: 39\n",
      "Epoch completed: 40\n",
      "Epoch completed: 41\n",
      "Epoch completed: 42\n",
      "Epoch completed: 43\n",
      "Epoch completed: 44\n",
      "Epoch completed: 45\n",
      "Epoch completed: 46\n",
      "Epoch completed: 47\n",
      "Epoch completed: 48\n",
      "Epoch completed: 49\n",
      "Epoch completed: 50\n",
      "Epoch completed: 51\n",
      "Epoch completed: 52\n",
      "Epoch completed: 53\n",
      "Epoch completed: 54\n",
      "Epoch completed: 55\n",
      "Epoch completed: 56\n",
      "Epoch completed: 57\n",
      "Epoch completed: 58\n",
      "Epoch completed: 59\n",
      "Epoch completed: 60\n",
      "Epoch completed: 61\n",
      "Epoch completed: 62\n",
      "Epoch completed: 63\n",
      "Epoch completed: 64\n",
      "Epoch completed: 65\n",
      "Epoch completed: 66\n",
      "Epoch completed: 67\n",
      "Epoch completed: 68\n",
      "Epoch completed: 69\n",
      "Epoch completed: 70\n",
      "Epoch completed: 71\n",
      "Epoch completed: 72\n",
      "Epoch completed: 73\n",
      "Epoch completed: 74\n",
      "Epoch completed: 75\n",
      "Epoch completed: 76\n",
      "Epoch completed: 77\n",
      "Epoch completed: 78\n",
      "Epoch completed: 79\n",
      "Epoch completed: 80\n",
      "Epoch completed: 81\n",
      "Epoch completed: 82\n",
      "Epoch completed: 83\n",
      "Epoch completed: 84\n",
      "Epoch completed: 85\n",
      "Epoch completed: 86\n",
      "Epoch completed: 87\n",
      "Epoch completed: 88\n",
      "Epoch completed: 89\n",
      "Epoch completed: 90\n",
      "Epoch completed: 91\n",
      "Epoch completed: 92\n",
      "Epoch completed: 93\n",
      "Epoch completed: 94\n",
      "Epoch completed: 95\n",
      "Epoch completed: 96\n",
      "Epoch completed: 97\n",
      "Epoch completed: 98\n",
      "Epoch completed: 99\n",
      "Epoch completed: 100\n"
     ]
    }
   ],
   "source": [
    "# Open the file for writing loss\n",
    "ffnn_loss_file_name = 'final.csv'\n",
    "f = open(ffnn_loss_file_name,'w')\n",
    "f.write('iter, loss')\n",
    "f.write('\\n')\n",
    "losses = []\n",
    "iter = 0\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    #print(\"1\")\n",
    "    if (epoch+1) % 1 == 0:\n",
    "  \n",
    "      #print(\"2\")\n",
    "      print(\"Epoch completed: \" + str(epoch+1))\n",
    "    train_loss = 0\n",
    "    for index, row in X_train.iterrows():\n",
    "      if index % 1000 == 0:\n",
    "        # Clearing the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        #print(index)\n",
    "        #print(row)\n",
    "        # Make the bag of words vector for stemmed tokens \n",
    "        bow_vec = make_bow_vector(r_dict, row['stemmed_tokens'])\n",
    "       \n",
    "        # Forward pass to get output\n",
    "        probs = ff_nn_bow_model(bow_vec)\n",
    "\n",
    "        # Get the target label\n",
    "        target = make_target(Y_train['sentiment'][index])\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = loss_function(probs, target)\n",
    "        # Accumulating the loss over time\n",
    "        train_loss += loss.item()\n",
    "        #print(\"3\")\n",
    "        optimizer.zero_grad()\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "       \n",
    "\n",
    "    with open('final.csv', 'w') as csvfile:\n",
    "      cwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "      cwriter.writerow(str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
    "\n",
    "    \n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxOts-Bc_At-",
    "outputId": "0b97abe5-34d7-4ef2-8ff5-ad29326e1c62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.75     14035\n",
      "           2       0.74      0.79      0.76     14073\n",
      "\n",
      "    accuracy                           0.76     28108\n",
      "   macro avg       0.76      0.76      0.76     28108\n",
      "weighted avg       0.76      0.76      0.76     28108\n",
      "\n",
      "0\n",
      "Index(['1 0 0 ', ' 0 . 0 0 0 9 2 3 3 8 2 6 8 4 0 9 0 3 9 4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "bow_ff_nn_predictions = []\n",
    "original_lables_ff_bow = []\n",
    "with torch.no_grad():\n",
    "    for index, row in X_test.iterrows():\n",
    "        bow_vec = make_bow_vector(r_dict, row['stemmed_tokens'])\n",
    "        probs = ff_nn_bow_model(bow_vec)\n",
    "        bow_ff_nn_predictions.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
    "        original_lables_ff_bow.append(make_target(Y_test['sentiment'][index]).cpu().numpy()[0])\n",
    "print(classification_report(original_lables_ff_bow,bow_ff_nn_predictions))\n",
    "ffnn_loss_df = pd.read_csv(ffnn_loss_file_name)\n",
    "\n",
    "\n",
    "print(len(ffnn_loss_df))\n",
    "print(ffnn_loss_df.columns)\n",
    "#ffnn_plt_500_padding_100_epochs = ffnn_loss_df[' loss'].plot()\n",
    "#fig = ffnn_plt_500_padding_100_epochs.get_figure()\n",
    "#fig"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of FFNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
